{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Part A: Build a classification model using text data"
      ],
      "metadata": {
        "id": "IH-tby-NWNle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##For Part A, you will be solving a text classification task. The training data is stored in the Homework 4 Data folder. The data consists of headlines that have been labeled for whether they are clickbait.\n",
        "1.\n",
        "Import the data. The headlines will become your vectorized X matrix, and the labels indicate a binary classification (clickbait or not)."
      ],
      "metadata": {
        "id": "u7aFM0gKWK6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('text_training_data.csv')\n",
        "text_data = data['headline'].values\n",
        "labels = data['label'].values\n",
        "\n",
        "# Convert labels to numeric format\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Print data information\n",
        "print(\"type of text_data: {}\".format(type(text_data)))\n",
        "print(\"length of text_data: {}\".format(len(text_data)))\n",
        "print(\"class balance: {}\".format(np.bincount(y)))\n",
        "print(\"\\ntext_data[1]:\\n{}\".format(text_data[1]))"
      ],
      "metadata": {
        "id": "_JJkwXLoWcrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b303333e-3a52-4eeb-d681-abaafbb53d1f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of text_data: <class 'numpy.ndarray'>\n",
            "length of text_data: 24979\n",
            "class balance: [12201 12778]\n",
            "\n",
            "text_data[1]:\n",
            "CIT Posts Eighth Loss in a Row\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Convert the headline data into an X feature matrix using a simple bag of words approach."
      ],
      "metadata": {
        "id": "DY4Q0MqvZL6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_train, text_test, y_train, y_test = train_test_split(\n",
        "    text_data, y, stratify=y, random_state=0)\n",
        "\n",
        "# Create basic bag of words vectorizer\n",
        "vect = CountVectorizer()\n",
        "\n",
        "# Transform text into bag of words feature matrix\n",
        "X_train = vect.fit_transform(text_train)\n",
        "X_test = vect.transform(text_test)\n",
        "\n",
        "# Print information about the feature matrix\n",
        "print(\"\\nFeatures shape: {}\".format(X_train.shape))\n",
        "print(\"Number of features: {}\".format(len(vect.get_feature_names_out())))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK6NhBhcZm-x",
        "outputId": "aa028c0b-fdf1-4a3d-9bdc-4fbe4a636d90"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features shape: (18734, 17883)\n",
            "Number of features: 17883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Run logistic regression to predict clickbait headlines. Remember to train_test_split your data and use GridSearchCV to find the best value of C. You should evaluate your data with F1 scoring."
      ],
      "metadata": {
        "id": "5LeHKnqRaQvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "grid = GridSearchCV(\n",
        "    LogisticRegression(max_iter=1000),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='f1'\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Print results of first model\n",
        "print(\"\\nModel 1 (Basic Bag of Words) Results:\")\n",
        "print(\"Best C:\", grid.best_params_['C'])\n",
        "print(\"Best cross-validation F1 score: {:.3f}\".format(grid.best_score_))\n",
        "print(\"Test set F1 score: {:.3f}\".format(\n",
        "    f1_score(y_test, grid.predict(X_test))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmEGEaHvZOuS",
        "outputId": "d5d60c8c-51ed-48ab-c8c2-45fad1056eba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model 1 (Basic Bag of Words) Results:\n",
            "Best C: 10\n",
            "Best cross-validation F1 score: 0.969\n",
            "Test set F1 score: 0.976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Run 2 more logistic regression models by changing the vectorization approach (e.g. using n-grams, stop_words, and other techniques we discussed). In both cases, keep your logistic regression step the same. Only change how you're generating the X matrix from the text data."
      ],
      "metadata": {
        "id": "5CX_6dnbaa2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: Using n-grams\n",
        "print(\"\\nModel 2 (N-grams):\")\n",
        "vect_ngram = CountVectorizer(ngram_range=(1, 2))\n",
        "X_train_ngram = vect_ngram.fit_transform(text_train)\n",
        "X_test_ngram = vect_ngram.transform(text_test)\n",
        "\n",
        "grid.fit(X_train_ngram, y_train)\n",
        "print(\"Best C:\", grid.best_params_['C'])\n",
        "print(\"Best cross-validation F1 score: {:.3f}\".format(grid.best_score_))\n",
        "print(\"Test set F1 score: {:.3f}\".format(\n",
        "    f1_score(y_test, grid.predict(X_test_ngram))))\n",
        "\n",
        "# Model 3: Using stop words and min_df\n",
        "print(\"\\nModel 3 (Stop Words + min_df):\")\n",
        "vect_stop = CountVectorizer(stop_words='english', min_df=5)\n",
        "X_train_stop = vect_stop.fit_transform(text_train)\n",
        "X_test_stop = vect_stop.transform(text_test)\n",
        "\n",
        "grid.fit(X_train_stop, y_train)\n",
        "print(\"Best C:\", grid.best_params_['C'])\n",
        "print(\"Best cross-validation F1 score: {:.3f}\".format(grid.best_score_))\n",
        "print(\"Test set F1 score: {:.3f}\".format(\n",
        "    f1_score(y_test, grid.predict(X_test_stop))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZgnflX8aeiD",
        "outputId": "34fba980-87ce-4815-d14e-bbdd014b94cc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model 2 (N-grams):\n",
            "Best C: 100\n",
            "Best cross-validation F1 score: 0.969\n",
            "Test set F1 score: 0.976\n",
            "\n",
            "Model 3 (Stop Words + min_df):\n",
            "Best C: 1\n",
            "Best cross-validation F1 score: 0.946\n",
            "Test set F1 score: 0.948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Which of your 3 models performed best? What are the most significant coefficients in each, and how do they compare?"
      ],
      "metadata": {
        "id": "31_jP5NHanCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_top_features(model, feature_names, n=10):\n",
        "    \"\"\"Print most significant coefficients for each class\"\"\"\n",
        "    coef = model.best_estimator_.coef_[0]\n",
        "    top_positive = np.argsort(coef)[-n:]\n",
        "    top_negative = np.argsort(coef)[:n]\n",
        "\n",
        "    print(\"\\nTop clickbait indicators:\")\n",
        "    for idx in reversed(top_positive):\n",
        "        print(f\"{feature_names[idx]}: {coef[idx]:.3f}\")\n",
        "\n",
        "    print(\"\\nTop non-clickbait indicators:\")\n",
        "    for idx in reversed(top_negative):\n",
        "        print(f\"{feature_names[idx]}: {coef[idx]:.3f}\")\n",
        "\n",
        "# Print top features for each model\n",
        "print(\"\\nModel 1 Important Features:\")\n",
        "print_top_features(grid, vect.get_feature_names_out())\n",
        "\n",
        "print(\"\\nModel 2 Important Features:\")\n",
        "print_top_features(grid, vect_ngram.get_feature_names_out())\n",
        "\n",
        "print(\"\\nModel 3 Important Features:\")\n",
        "print_top_features(grid, vect_stop.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVEyGiteaqK9",
        "outputId": "e62ec39d-2f93-4a55-d8ec-41e4c8802578"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model 1 Important Features:\n",
            "\n",
            "Top clickbait indicators:\n",
            "armenian: 2.696\n",
            "bondholder: 2.348\n",
            "dawn: 2.235\n",
            "decisive: 2.146\n",
            "bonkers: 2.140\n",
            "blazing: 2.031\n",
            "celebrity: 1.981\n",
            "abduction: 1.947\n",
            "abductor: 1.924\n",
            "camping: 1.880\n",
            "\n",
            "Top non-clickbait indicators:\n",
            "128: -2.323\n",
            "cigarette: -2.333\n",
            "126: -2.382\n",
            "covergirl: -2.394\n",
            "billingham: -2.402\n",
            "123: -2.714\n",
            "alexander: -2.881\n",
            "222: -3.011\n",
            "beauty: -3.053\n",
            "bonus: -3.155\n",
            "\n",
            "Model 2 Important Features:\n",
            "\n",
            "Top clickbait indicators:\n",
            "18 celebs: 2.696\n",
            "22 super: 2.348\n",
            "according to: 2.235\n",
            "aced no: 2.146\n",
            "22 years: 2.140\n",
            "21 quotes: 2.031\n",
            "34 more: 1.981\n",
            "12 creative: 1.947\n",
            "12 days: 1.924\n",
            "29 husbands: 1.880\n",
            "\n",
            "Top non-clickbait indicators:\n",
            "000 protest: -2.323\n",
            "50 dead: -2.333\n",
            "000 phobos: -2.382\n",
            "about lizzie: -2.394\n",
            "21 buttons: -2.402\n",
            "000 pennies: -2.714\n",
            "15 pictures: -2.881\n",
            "10 reasons: -3.011\n",
            "2009 held: -3.053\n",
            "225: -3.155\n",
            "\n",
            "Model 3 Important Features:\n",
            "\n",
            "Top clickbait indicators:\n",
            "dies: 2.696\n",
            "kills: 2.348\n",
            "wins: 2.235\n",
            "zealand: 2.146\n",
            "knicks: 2.140\n",
            "iraq: 2.031\n",
            "police: 1.981\n",
            "australia: 1.947\n",
            "australian: 1.924\n",
            "obama: 1.880\n",
            "\n",
            "Top non-clickbait indicators:\n",
            "23: -2.323\n",
            "remember: -2.333\n",
            "21: -2.382\n",
            "things: -2.394\n",
            "identify: -2.402\n",
            "2015: -2.714\n",
            "character: -2.881\n",
            "actually: -3.011\n",
            "guess: -3.053\n",
            "know: -3.155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the coefficient analysis of all three models, Model 2 (using N-grams) performed best at detecting clickbait headlines. While Model 1's basic bag-of-words approach identified emotional single words (like \"bonkers\" and \"blazing\" for clickbait, and numbers like \"128\" and \"222\" for non-clickbait), and Model 3's stop-words-removed approach focused on action verbs (like \"dies\" and \"kills\" for clickbait, and \"remember\" and \"know\" for non-clickbait), Model 2's n-gram approach was most effective because it captured important contextual patterns. It identified typical clickbait structures like number-word combinations (\"18 celebs\", \"22 super\") as strong clickbait indicators, while phrases like \"000 protest\" and \"50 dead\" signaled non-clickbait content. The coefficients in Model 2 showed the highest ability to distinguish between clickbait and legitimate number usage, making it the most reliable for identifying the nuanced ways clickbait headlines are constructed."
      ],
      "metadata": {
        "id": "vu6jSqsdgbcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part B: Build a Predictive Neural Network Using Keras"
      ],
      "metadata": {
        "id": "Pt7yQqyog-zr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Part B, you will run a multilayer perceptron on the iris dataset to predict flower type."
      ],
      "metadata": {
        "id": "KZqopgKJhBlB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the data. Data can be imported directly using pd.read_csv() and the link http://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv."
      ],
      "metadata": {
        "id": "K5wb-1yQhDa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "iris_data = pd.read_csv('http://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv')\n",
        "\n",
        "print(\"Dataset structure:\")\n",
        "print(iris_data.head())\n",
        "print(\"\\nColumn names:\", iris_data.columns)\n",
        "\n",
        "# Prepare features (X) and target (y)\n",
        "# Note: We select only the numeric columns for features\n",
        "X = iris_data[['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']].values\n",
        "# Convert species to numeric categories\n",
        "y = pd.Categorical(iris_data['Species']).codes\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert target to categorical (one-hot encoding)\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "# Print shapes to verify data structure\n",
        "print(\"\\nData shapes:\")\n",
        "print(f\"X_train shape: {X_train_scaled.shape}\")\n",
        "print(f\"y_train shape: {y_train_cat.shape}\")\n",
        "print(f\"X_test shape: {X_test_scaled.shape}\")\n",
        "print(f\"y_test shape: {y_test_cat.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpinXRhAfFo2",
        "outputId": "e170c2b3-33aa-4244-b89a-3c05669d6fe3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset structure:\n",
            "   rownames  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
            "0         1           5.1          3.5           1.4          0.2  setosa\n",
            "1         2           4.9          3.0           1.4          0.2  setosa\n",
            "2         3           4.7          3.2           1.3          0.2  setosa\n",
            "3         4           4.6          3.1           1.5          0.2  setosa\n",
            "4         5           5.0          3.6           1.4          0.2  setosa\n",
            "\n",
            "Column names: Index(['rownames', 'Sepal.Length', 'Sepal.Width', 'Petal.Length',\n",
            "       'Petal.Width', 'Species'],\n",
            "      dtype='object')\n",
            "\n",
            "Data shapes:\n",
            "X_train shape: (120, 4)\n",
            "y_train shape: (120, 3)\n",
            "X_test shape: (30, 4)\n",
            "y_test shape: (30, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Using the Sequential interface in Keras, build a model with 2 hidden layers with 16 neurons in each. Compile and fit the model. Assess its performance using accuracy on data that has been train_test_split."
      ],
      "metadata": {
        "id": "15TZ0GDOAVKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_1():\n",
        "    model = Sequential([\n",
        "        Dense(16, input_shape=(4,), activation='relu'),  # First hidden layer\n",
        "        Dense(16, activation='relu'),                    # Second hidden layer\n",
        "        Dense(3, activation='softmax')                   # Output layer (3 classes)\n",
        "    ])\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "nuCcjBhtAqg0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Run 2 additional models using different numbers of hidden layers and/or hidden neurons."
      ],
      "metadata": {
        "id": "kWUebnehA0Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_2():\n",
        "    # Smaller model with 1 hidden layer\n",
        "    model = Sequential([\n",
        "        Dense(8, input_shape=(4,), activation='relu'),   # Single hidden layer\n",
        "        Dense(3, activation='softmax')                   # Output layer\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_model_3():\n",
        "    # Larger model with 3 hidden layers\n",
        "    model = Sequential([\n",
        "        Dense(32, input_shape=(4,), activation='relu'),  # First hidden layer\n",
        "        Dense(16, activation='relu'),                    # Second hidden layer\n",
        "        Dense(8, activation='relu'),                     # Third hidden layer\n",
        "        Dense(3, activation='softmax')                   # Output layer\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "bXvkxlUuA3H_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does the performance compare between your 3 models?"
      ],
      "metadata": {
        "id": "Qdq2wbnHBCCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(model, model_name):\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_scaled, y_train_cat,\n",
        "                       epochs=50,\n",
        "                       batch_size=32,\n",
        "                       validation_split=0.2,\n",
        "                       verbose=1)  # Changed to 1 to see training progress\n",
        "\n",
        "    # Evaluate the model\n",
        "    score = model.evaluate(X_test_scaled, y_test_cat, verbose=0)\n",
        "    print(f\"\\n{model_name} Test Accuracy: {score[1]:.3f}\")\n",
        "    return score[1]\n",
        "\n",
        "# Create and train all models\n",
        "print(\"\\nTraining Model 1...\")\n",
        "model1 = create_model_1()\n",
        "accuracy1 = train_and_evaluate_model(model1, \"Model 1 (2 layers, 16 neurons each)\")\n",
        "\n",
        "print(\"\\nTraining Model 2...\")\n",
        "model2 = create_model_2()\n",
        "accuracy2 = train_and_evaluate_model(model2, \"Model 2 (1 layer, 8 neurons)\")\n",
        "\n",
        "print(\"\\nTraining Model 3...\")\n",
        "model3 = create_model_3()\n",
        "accuracy3 = train_and_evaluate_model(model3, \"Model 3 (3 layers, 32-16-8 neurons)\")\n",
        "\n",
        "# Print comparison summary\n",
        "print(\"\\nModel Comparison Summary:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Model 1 (2 layers, 16 neurons each): {accuracy1:.3f}\")\n",
        "print(f\"Model 2 (1 layer, 8 neurons): {accuracy2:.3f}\")\n",
        "print(f\"Model 3 (3 layers, 32-16-8 neurons): {accuracy3:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9lWgtA5BEME",
        "outputId": "271aad0d-ccf9-4a07-c255-22aa0b7b4944"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Model 1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.1927 - loss: 1.1345 - val_accuracy: 0.3333 - val_loss: 1.0827\n",
            "Epoch 2/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2643 - loss: 1.1011 - val_accuracy: 0.4167 - val_loss: 1.0625\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3672 - loss: 1.0716 - val_accuracy: 0.4583 - val_loss: 1.0440\n",
            "Epoch 4/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3385 - loss: 1.0701 - val_accuracy: 0.4583 - val_loss: 1.0270\n",
            "Epoch 5/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3997 - loss: 1.0434 - val_accuracy: 0.5000 - val_loss: 1.0101\n",
            "Epoch 6/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4531 - loss: 1.0171 - val_accuracy: 0.5417 - val_loss: 0.9937\n",
            "Epoch 7/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4922 - loss: 0.9943 - val_accuracy: 0.6250 - val_loss: 0.9772\n",
            "Epoch 8/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4831 - loss: 0.9854 - val_accuracy: 0.6250 - val_loss: 0.9613\n",
            "Epoch 9/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5820 - loss: 0.9440 - val_accuracy: 0.6250 - val_loss: 0.9451\n",
            "Epoch 10/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5911 - loss: 0.9433 - val_accuracy: 0.6250 - val_loss: 0.9297\n",
            "Epoch 11/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5872 - loss: 0.9272 - val_accuracy: 0.6667 - val_loss: 0.9146\n",
            "Epoch 12/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6315 - loss: 0.9060 - val_accuracy: 0.7917 - val_loss: 0.8993\n",
            "Epoch 13/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7096 - loss: 0.8815 - val_accuracy: 0.7917 - val_loss: 0.8839\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7344 - loss: 0.8641 - val_accuracy: 0.7917 - val_loss: 0.8685\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7474 - loss: 0.8535 - val_accuracy: 0.8333 - val_loss: 0.8532\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7995 - loss: 0.8265 - val_accuracy: 0.8750 - val_loss: 0.8375\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8203 - loss: 0.8132 - val_accuracy: 0.9167 - val_loss: 0.8219\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8177 - loss: 0.8006 - val_accuracy: 0.9167 - val_loss: 0.8062\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8216 - loss: 0.7900 - val_accuracy: 0.9167 - val_loss: 0.7900\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8594 - loss: 0.7729 - val_accuracy: 0.9167 - val_loss: 0.7738\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8281 - loss: 0.7563 - val_accuracy: 0.9167 - val_loss: 0.7583\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8789 - loss: 0.7073 - val_accuracy: 0.9167 - val_loss: 0.7425\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8125 - loss: 0.7270 - val_accuracy: 0.9167 - val_loss: 0.7272\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8672 - loss: 0.6866 - val_accuracy: 0.8750 - val_loss: 0.7114\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8555 - loss: 0.6610 - val_accuracy: 0.8750 - val_loss: 0.6964\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8594 - loss: 0.6550 - val_accuracy: 0.8750 - val_loss: 0.6813\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8516 - loss: 0.6648 - val_accuracy: 0.8750 - val_loss: 0.6665\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8438 - loss: 0.6533 - val_accuracy: 0.8750 - val_loss: 0.6517\n",
            "Epoch 29/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8516 - loss: 0.6127 - val_accuracy: 0.8750 - val_loss: 0.6367\n",
            "Epoch 30/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8359 - loss: 0.6176 - val_accuracy: 0.8750 - val_loss: 0.6225\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8516 - loss: 0.5910 - val_accuracy: 0.8750 - val_loss: 0.6086\n",
            "Epoch 32/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8359 - loss: 0.6073 - val_accuracy: 0.8750 - val_loss: 0.5949\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8438 - loss: 0.5808 - val_accuracy: 0.8750 - val_loss: 0.5821\n",
            "Epoch 34/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8242 - loss: 0.5790 - val_accuracy: 0.8750 - val_loss: 0.5692\n",
            "Epoch 35/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8164 - loss: 0.5693 - val_accuracy: 0.9167 - val_loss: 0.5571\n",
            "Epoch 36/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8451 - loss: 0.5470 - val_accuracy: 0.9167 - val_loss: 0.5450\n",
            "Epoch 37/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8841 - loss: 0.4923 - val_accuracy: 0.9167 - val_loss: 0.5326\n",
            "Epoch 38/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8646 - loss: 0.4908 - val_accuracy: 0.9167 - val_loss: 0.5208\n",
            "Epoch 39/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8294 - loss: 0.5076 - val_accuracy: 0.9167 - val_loss: 0.5099\n",
            "Epoch 40/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8607 - loss: 0.4884 - val_accuracy: 0.9167 - val_loss: 0.4989\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8724 - loss: 0.4684 - val_accuracy: 0.9167 - val_loss: 0.4876\n",
            "Epoch 42/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8646 - loss: 0.4807 - val_accuracy: 0.9167 - val_loss: 0.4774\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8685 - loss: 0.4413 - val_accuracy: 0.9167 - val_loss: 0.4674\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8698 - loss: 0.4446 - val_accuracy: 0.9167 - val_loss: 0.4581\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8477 - loss: 0.4631 - val_accuracy: 0.9167 - val_loss: 0.4491\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8867 - loss: 0.4459 - val_accuracy: 0.9167 - val_loss: 0.4403\n",
            "Epoch 47/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8672 - loss: 0.4358 - val_accuracy: 0.9167 - val_loss: 0.4315\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8750 - loss: 0.4037 - val_accuracy: 0.9167 - val_loss: 0.4231\n",
            "Epoch 49/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8438 - loss: 0.4390 - val_accuracy: 0.9167 - val_loss: 0.4154\n",
            "Epoch 50/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8672 - loss: 0.4032 - val_accuracy: 0.9167 - val_loss: 0.4073\n",
            "\n",
            "Model 1 (2 layers, 16 neurons each) Test Accuracy: 0.933\n",
            "\n",
            "Training Model 2...\n",
            "Epoch 1/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.2826 - loss: 1.1859 - val_accuracy: 0.5000 - val_loss: 1.0267\n",
            "Epoch 2/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3568 - loss: 1.1466 - val_accuracy: 0.5000 - val_loss: 1.0143\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3411 - loss: 1.1843 - val_accuracy: 0.5417 - val_loss: 1.0022\n",
            "Epoch 4/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3073 - loss: 1.1589 - val_accuracy: 0.5417 - val_loss: 0.9902\n",
            "Epoch 5/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3203 - loss: 1.1466 - val_accuracy: 0.5417 - val_loss: 0.9788\n",
            "Epoch 6/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4036 - loss: 1.1065 - val_accuracy: 0.5417 - val_loss: 0.9670\n",
            "Epoch 7/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3646 - loss: 1.0868 - val_accuracy: 0.5417 - val_loss: 0.9553\n",
            "Epoch 8/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3490 - loss: 1.0966 - val_accuracy: 0.5417 - val_loss: 0.9442\n",
            "Epoch 9/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3958 - loss: 1.0755 - val_accuracy: 0.5417 - val_loss: 0.9330\n",
            "Epoch 10/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2995 - loss: 1.0833 - val_accuracy: 0.5417 - val_loss: 0.9218\n",
            "Epoch 11/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3411 - loss: 1.0693 - val_accuracy: 0.5417 - val_loss: 0.9109\n",
            "Epoch 12/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3333 - loss: 1.0619 - val_accuracy: 0.5833 - val_loss: 0.9001\n",
            "Epoch 13/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4049 - loss: 1.0149 - val_accuracy: 0.5833 - val_loss: 0.8893\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3737 - loss: 1.0221 - val_accuracy: 0.5833 - val_loss: 0.8787\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3984 - loss: 1.0060 - val_accuracy: 0.6250 - val_loss: 0.8684\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3724 - loss: 1.0169 - val_accuracy: 0.7083 - val_loss: 0.8581\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3750 - loss: 1.0118 - val_accuracy: 0.7083 - val_loss: 0.8478\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3945 - loss: 0.9896 - val_accuracy: 0.7083 - val_loss: 0.8376\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4362 - loss: 0.9711 - val_accuracy: 0.7083 - val_loss: 0.8279\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4570 - loss: 0.9680 - val_accuracy: 0.7083 - val_loss: 0.8181\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4714 - loss: 0.9519 - val_accuracy: 0.7083 - val_loss: 0.8085\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5169 - loss: 0.9318 - val_accuracy: 0.7083 - val_loss: 0.7989\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4961 - loss: 0.9329 - val_accuracy: 0.7500 - val_loss: 0.7895\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5781 - loss: 0.9115 - val_accuracy: 0.7500 - val_loss: 0.7802\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5534 - loss: 0.9194 - val_accuracy: 0.7917 - val_loss: 0.7708\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6263 - loss: 0.9084 - val_accuracy: 0.7917 - val_loss: 0.7619\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6224 - loss: 0.8915 - val_accuracy: 0.7917 - val_loss: 0.7528\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6224 - loss: 0.8579 - val_accuracy: 0.7917 - val_loss: 0.7437\n",
            "Epoch 29/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6276 - loss: 0.8509 - val_accuracy: 0.7917 - val_loss: 0.7347\n",
            "Epoch 30/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6224 - loss: 0.8694 - val_accuracy: 0.7917 - val_loss: 0.7264\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6419 - loss: 0.8427 - val_accuracy: 0.8333 - val_loss: 0.7177\n",
            "Epoch 32/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6628 - loss: 0.8416 - val_accuracy: 0.8333 - val_loss: 0.7092\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6016 - loss: 0.8541 - val_accuracy: 0.8333 - val_loss: 0.7006\n",
            "Epoch 34/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6758 - loss: 0.8083 - val_accuracy: 0.8333 - val_loss: 0.6920\n",
            "Epoch 35/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6797 - loss: 0.8058 - val_accuracy: 0.8333 - val_loss: 0.6835\n",
            "Epoch 36/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6497 - loss: 0.7939 - val_accuracy: 0.7917 - val_loss: 0.6753\n",
            "Epoch 37/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6471 - loss: 0.7924 - val_accuracy: 0.7917 - val_loss: 0.6672\n",
            "Epoch 38/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6589 - loss: 0.7810 - val_accuracy: 0.8333 - val_loss: 0.6594\n",
            "Epoch 39/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7161 - loss: 0.7632 - val_accuracy: 0.8333 - val_loss: 0.6514\n",
            "Epoch 40/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6966 - loss: 0.7648 - val_accuracy: 0.8750 - val_loss: 0.6436\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6940 - loss: 0.7503 - val_accuracy: 0.8750 - val_loss: 0.6361\n",
            "Epoch 42/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7018 - loss: 0.7228 - val_accuracy: 0.8750 - val_loss: 0.6286\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6901 - loss: 0.7299 - val_accuracy: 0.8750 - val_loss: 0.6210\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7161 - loss: 0.7230 - val_accuracy: 0.8750 - val_loss: 0.6134\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7292 - loss: 0.7036 - val_accuracy: 0.8750 - val_loss: 0.6058\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7565 - loss: 0.6881 - val_accuracy: 0.8750 - val_loss: 0.5984\n",
            "Epoch 47/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7591 - loss: 0.7067 - val_accuracy: 0.8750 - val_loss: 0.5913\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7617 - loss: 0.6824 - val_accuracy: 0.9167 - val_loss: 0.5840\n",
            "Epoch 49/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7695 - loss: 0.6736 - val_accuracy: 0.9167 - val_loss: 0.5770\n",
            "Epoch 50/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8138 - loss: 0.6436 - val_accuracy: 0.9167 - val_loss: 0.5700\n",
            "\n",
            "Model 2 (1 layer, 8 neurons) Test Accuracy: 0.933\n",
            "\n",
            "Training Model 3...\n",
            "Epoch 1/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - accuracy: 0.0677 - loss: 1.1906 - val_accuracy: 0.0833 - val_loss: 1.2445\n",
            "Epoch 2/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0859 - loss: 1.1441 - val_accuracy: 0.1667 - val_loss: 1.1974\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2539 - loss: 1.0797 - val_accuracy: 0.2083 - val_loss: 1.1594\n",
            "Epoch 4/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3919 - loss: 1.0489 - val_accuracy: 0.2083 - val_loss: 1.1240\n",
            "Epoch 5/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3711 - loss: 1.0399 - val_accuracy: 0.2500 - val_loss: 1.0938\n",
            "Epoch 6/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4049 - loss: 0.9759 - val_accuracy: 0.2917 - val_loss: 1.0679\n",
            "Epoch 7/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5091 - loss: 0.9348 - val_accuracy: 0.2917 - val_loss: 1.0437\n",
            "Epoch 8/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4531 - loss: 0.9234 - val_accuracy: 0.2917 - val_loss: 1.0220\n",
            "Epoch 9/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4727 - loss: 0.9040 - val_accuracy: 0.3333 - val_loss: 1.0037\n",
            "Epoch 10/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4479 - loss: 0.8904 - val_accuracy: 0.3333 - val_loss: 0.9898\n",
            "Epoch 11/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4701 - loss: 0.8529 - val_accuracy: 0.3750 - val_loss: 0.9789\n",
            "Epoch 12/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4857 - loss: 0.8344 - val_accuracy: 0.3750 - val_loss: 0.9696\n",
            "Epoch 13/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5026 - loss: 0.8209 - val_accuracy: 0.3750 - val_loss: 0.9607\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5599 - loss: 0.8028 - val_accuracy: 0.3750 - val_loss: 0.9521\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5586 - loss: 0.7768 - val_accuracy: 0.4167 - val_loss: 0.9434\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5820 - loss: 0.7682 - val_accuracy: 0.4583 - val_loss: 0.9352\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5911 - loss: 0.7680 - val_accuracy: 0.4583 - val_loss: 0.9270\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5729 - loss: 0.7738 - val_accuracy: 0.4583 - val_loss: 0.9186\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5729 - loss: 0.7787 - val_accuracy: 0.4583 - val_loss: 0.9105\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6315 - loss: 0.7472 - val_accuracy: 0.4583 - val_loss: 0.9029\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6784 - loss: 0.7492 - val_accuracy: 0.4583 - val_loss: 0.8959\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6393 - loss: 0.7078 - val_accuracy: 0.4583 - val_loss: 0.8891\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6667 - loss: 0.7135 - val_accuracy: 0.4583 - val_loss: 0.8827\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6510 - loss: 0.7206 - val_accuracy: 0.4583 - val_loss: 0.8763\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6589 - loss: 0.7118 - val_accuracy: 0.4583 - val_loss: 0.8700\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6784 - loss: 0.6992 - val_accuracy: 0.4583 - val_loss: 0.8645\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6940 - loss: 0.6658 - val_accuracy: 0.4583 - val_loss: 0.8595\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6745 - loss: 0.6530 - val_accuracy: 0.4583 - val_loss: 0.8546\n",
            "Epoch 29/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7057 - loss: 0.6371 - val_accuracy: 0.4583 - val_loss: 0.8497\n",
            "Epoch 30/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6927 - loss: 0.6400 - val_accuracy: 0.4583 - val_loss: 0.8446\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6927 - loss: 0.6368 - val_accuracy: 0.4583 - val_loss: 0.8395\n",
            "Epoch 32/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7318 - loss: 0.6259 - val_accuracy: 0.4583 - val_loss: 0.8347\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7253 - loss: 0.6206 - val_accuracy: 0.4583 - val_loss: 0.8299\n",
            "Epoch 34/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6862 - loss: 0.6657 - val_accuracy: 0.4583 - val_loss: 0.8253\n",
            "Epoch 35/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7070 - loss: 0.6203 - val_accuracy: 0.4583 - val_loss: 0.8210\n",
            "Epoch 36/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7148 - loss: 0.6175 - val_accuracy: 0.4583 - val_loss: 0.8170\n",
            "Epoch 37/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7109 - loss: 0.6013 - val_accuracy: 0.5000 - val_loss: 0.8125\n",
            "Epoch 38/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7617 - loss: 0.5531 - val_accuracy: 0.5000 - val_loss: 0.8080\n",
            "Epoch 39/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7656 - loss: 0.5600 - val_accuracy: 0.5000 - val_loss: 0.8037\n",
            "Epoch 40/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7031 - loss: 0.6134 - val_accuracy: 0.5000 - val_loss: 0.7988\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7383 - loss: 0.5720 - val_accuracy: 0.5000 - val_loss: 0.7940\n",
            "Epoch 42/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7500 - loss: 0.5529 - val_accuracy: 0.5000 - val_loss: 0.7890\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6953 - loss: 0.5932 - val_accuracy: 0.5000 - val_loss: 0.7834\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7266 - loss: 0.5478 - val_accuracy: 0.5000 - val_loss: 0.7781\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7461 - loss: 0.5384 - val_accuracy: 0.5000 - val_loss: 0.7735\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6992 - loss: 0.5823 - val_accuracy: 0.5000 - val_loss: 0.7687\n",
            "Epoch 47/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7031 - loss: 0.5761 - val_accuracy: 0.5000 - val_loss: 0.7645\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6797 - loss: 0.5778 - val_accuracy: 0.5000 - val_loss: 0.7600\n",
            "Epoch 49/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7227 - loss: 0.5441 - val_accuracy: 0.5000 - val_loss: 0.7561\n",
            "Epoch 50/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7070 - loss: 0.5392 - val_accuracy: 0.5000 - val_loss: 0.7520\n",
            "\n",
            "Model 3 (3 layers, 32-16-8 neurons) Test Accuracy: 0.633\n",
            "\n",
            "Model Comparison Summary:\n",
            "--------------------------------------------------\n",
            "Model 1 (2 layers, 16 neurons each): 0.933\n",
            "Model 2 (1 layer, 8 neurons): 0.933\n",
            "Model 3 (3 layers, 32-16-8 neurons): 0.633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 utilized a moderate architecture with two hidden layers containing 16 neurons each, followed by a final output layer with 3 neurons (one for each Iris class). This model achieved a strong accuracy of 93.3% on the test data, demonstrating effective learning of the Iris classification patterns. Model 2 took a simpler approach with just one hidden layer of 8 neurons, and surprisingly matched Model 1's performance with the same 93.3% accuracy, suggesting that the Iris dataset's patterns are simple enough to be captured by a less complex architecture. Model 3 attempted a more sophisticated design with three hidden layers (32, 16, and 8 neurons respectively), but significantly underperformed with only 63.3% accuracy, likely due to overfitting and the model being unnecessarily complex for this straightforward classification task. These results emphasize a crucial lesson in neural network design: simpler architectures (like Model 2) can often perform just as well as or better than more complex ones, especially for relatively straightforward datasets like Iris classification."
      ],
      "metadata": {
        "id": "1OKu-TkmAFTK"
      }
    }
  ]
}